# ===================================================================
# LISTENER PODCAST APPLICATION - ENVIRONMENT CONFIGURATION
# ===================================================================
# 
# This file contains all environment variables needed for the
# Listener podcast application. Copy this file to .env.local for
# local development, or .env.production for production deployment.
#
# SECURITY NOTICE: Never commit real credentials to version control!
# The .env.local file is in .gitignore for this reason.
#
# SETUP TIME: Approximately 10-15 minutes for all credentials
# HELP: See ENVIRONMENT_SETUP.md for detailed setup instructions
# ===================================================================

# ===================================================================
# DATABASE & AUTHENTICATION (SUPABASE)
# ===================================================================
# Required for: Core application functionality, user auth, data storage
# Setup time: 2-3 minutes
# Priority: CRITICAL - App won't work without these
#
# How to get these credentials:
# 1. Go to https://supabase.com/dashboard
# 2. Select your project (or create one)
# 3. Go to Settings → API
# 4. Copy the URL and both keys
#
# SECURITY WARNING: Never expose SERVICE_ROLE_KEY in client-side code!
# It has admin privileges and can bypass all security rules.

SUPABASE_URL=https://<your-project-ref>.supabase.co
SUPABASE_ANON_KEY=<your_anon_key>
SUPABASE_SERVICE_ROLE_KEY=<your_service_role_key>

# Client-side Supabase configuration (for React/Vite)
# These MUST start with VITE_ to be accessible in the browser
# They should match the SUPABASE_* variables above
VITE_SUPABASE_URL=https://<your-project-ref>.supabase.co
VITE_SUPABASE_ANON_KEY=<your_anon_key>

# ===================================================================
# SPOTIFY API (PODCAST DISCOVERY & METADATA)
# ===================================================================
# Required for: Podcast search, metadata, episode discovery
# Setup time: 3-5 minutes
# Priority: CRITICAL - Primary source for podcast data
#
# How to get these credentials:
# 1. Go to https://developer.spotify.com/dashboard
# 2. Create a new app (any name/description)
# 3. Copy Client ID and Client Secret
# 4. Set redirect URI if needed: http://localhost:3000/callback
#
# PKCE (Proof Key for Code Exchange) - Modern OAuth2 flow
# Set to "true" for enhanced security, "false" for basic flow

SPOTIFY_CLIENT_ID=<your_spotify_client_id>
SPOTIFY_CLIENT_SECRET=<your_spotify_client_secret>
SPOTIFY_USE_PKCE=true

# ===================================================================
# TRANSCRIPT PROVIDERS
# ===================================================================

# -------------------------------------------------------------------
# TADDY API (PRIMARY TRANSCRIPT PROVIDER)
# -------------------------------------------------------------------
# Required for: Podcast episode transcript retrieval
# Setup time: 2-3 minutes
# Priority: HIGH - Primary transcript source
#
# How to get API key:
# 1. Sign up at https://taddy.org
# 2. Go to https://taddy.org/developers/api-docs
# 3. Generate API key from your dashboard
#
# PRICING TIERS:
# - Free Tier: 1,000 requests/month, pregenerated transcripts only
# - Business Tier: Higher limits, on-demand generation, speaker diarization
#
# USAGE IN APP:
# - Transcript lookup for new episodes
# - Fallback when other providers fail
# - Batch processing for historical episodes
#
# DOCUMENTATION: https://docs.taddy.org/api-reference
# DASHBOARD: https://taddy.org/dashboard

TADDY_API_KEY=<your_taddy_api_key>

# -------------------------------------------------------------------
# DEEPGRAM API (SPEECH-TO-TEXT FALLBACK)
# -------------------------------------------------------------------
# Required for: Transcript generation when Taddy doesn't have transcripts
# Setup time: 2-3 minutes
# Priority: MEDIUM - Fallback transcript provider
#
# How to get API key:
# 1. Sign up at https://deepgram.com
# 2. Go to API Keys section in dashboard
# 3. Create new API key
#
# PRICING: $200 free credit to start, then pay-per-use
# FEATURES: Real-time and batch transcription, multiple languages

DEEPGRAM_API_KEY=<your_deepgram_api_key>

# ===================================================================
# LLM PROVIDERS (EPISODE NOTES GENERATION)
# ===================================================================

# -------------------------------------------------------------------
# GOOGLE GEMINI API (EPISODE NOTES GENERATION)
# -------------------------------------------------------------------
# Required for: Generating episode notes and themes from transcripts
# Setup time: 2-3 minutes
# Priority: HIGH - Primary LLM for episode notes feature
#
# How to get API key:
# 1. Go to https://aistudio.google.com/app/apikey
# 2. Create a new API key for your project
# 3. Copy the API key
#
# PRICING: Free tier includes generous limits for testing
# FEATURES: Gemini 1.5 Flash optimized for speed and cost-effectiveness
#
# Model Configuration:
# - Default model: models/gemini-1.5-flash-latest
# - Override with GEMINI_MODEL_NAME if needed
# - Supports large context windows suitable for podcast transcripts

GEMINI_API_KEY=<your_gemini_api_key>

# Optional: Override the default Gemini model
# Default: models/gemini-1.5-flash-latest
# Alternatives: models/gemini-1.5-flash, models/gemini-1.5-pro
GEMINI_MODEL_NAME=models/gemini-1.5-flash-latest

# ===================================================================
# EMAIL SERVICE (NEWSLETTER DELIVERY)
# ===================================================================

# -------------------------------------------------------------------
# RESEND API (EMAIL SERVICE)
# -------------------------------------------------------------------
# Required for: Sending newsletter emails to users
# Setup time: 2-3 minutes
# Priority: HIGH - Essential for newsletter delivery
#
# How to get API key:
# 1. Sign up at https://resend.com
# 2. Go to API Keys section in dashboard
# 3. Create new API key
#
# PRICING:
# - Free tier: 3,000 emails/month
# - Paid tier: $0.80 per 1,000 emails
#
# FEATURES:
# - Reliable email delivery with high deliverability
# - HTML email support with responsive templates
# - Email tracking and analytics
# - Domain verification for production use
#
# DOMAIN SETUP:
# - For production: Verify your domain in Resend dashboard
# - For development: Use Resend's sandbox domain or verify your domain
# - SEND_FROM_EMAIL must be from a verified domain in production
#
# DOCUMENTATION: https://resend.com/docs
# DASHBOARD: https://resend.com/dashboard

RESEND_API_KEY=<your_resend_api_key>

# Email address to send newsletters from
# SECURITY: Must be from a verified domain in production
# DEVELOPMENT: Can use Resend's sandbox domain for testing
SEND_FROM_EMAIL=<your_sender_email>

# Test email address for L10 testing mode
# Used when SEND_WORKER_L10=true to send test emails
# Can be any valid email address
TEST_RECEIVER_EMAIL=test@example.com

# ===================================================================
# PODCAST DISCOVERY & RSS FEEDS
# ===================================================================

# -------------------------------------------------------------------
# PODCAST INDEX API (RSS FEED DISCOVERY)
# -------------------------------------------------------------------
# Required for: RSS feed URLs, podcast metadata, directory search
# Setup time: 2-3 minutes
# Priority: HIGH - Essential for RSS feed discovery
#
# How to get credentials:
# 1. Sign up at https://podcastindex.org
# 2. Go to API section
# 3. Generate API key and secret
#
# FEATURES: Free tier with rate limits, comprehensive podcast database

PODCASTINDEX_KEY=<your_podcastindex_key>
PODCASTINDEX_SECRET=<your_podcastindex_secret>

# User Agent for API requests (identifies your app)
# Format: AppName/Version +URL
USER_AGENT=ListenerApp/1.0 +https://github.com/your-org/listener

# ===================================================================
# SERVER CONFIGURATION
# ===================================================================

# -------------------------------------------------------------------
# BASIC SERVER SETTINGS
# -------------------------------------------------------------------
# Environment: development, production, or test
NODE_ENV=development

# Port for the server to run on
# Default: 3001 (client runs on 3000)
PORT=3001

# -------------------------------------------------------------------
# SECURITY CONFIGURATION
# -------------------------------------------------------------------
# JWT Secret: Used for signing authentication tokens
# SECURITY: Must be at least 32 characters long and cryptographically secure
# Generate with: openssl rand -hex 32
JWT_SECRET=<your_super_secret_jwt_key_here>

# Token Encryption Key: Used for encrypting sensitive tokens
# SECURITY: Must be exactly 32 characters long
# Generate with: openssl rand -hex 16
TOKEN_ENC_KEY=<your_32_character_encryption_key>

# -------------------------------------------------------------------
# LOGGING CONFIGURATION
# -------------------------------------------------------------------
# Log Level: Controls verbosity of application logs
# Options: debug, info, warn, error
# Recommended: info for production, debug for development
LOG_LEVEL=info

# Structured Logging: JSON format for production, human-readable for development
# Options: true (JSON), false (human-readable)
STRUCTURED_LOGGING=false

# ===================================================================
# BACKGROUND JOBS & SCHEDULING
# ===================================================================

# -------------------------------------------------------------------
# DAILY REFRESH JOB
# -------------------------------------------------------------------
# Automatically refreshes podcast subscriptions daily
# This job checks for new episodes and updates podcast metadata

# Enable/disable the daily refresh job
DAILY_REFRESH_ENABLED=true

# Cron schedule for daily refresh (default: 6 AM daily)
# Format: minute hour day-of-month month day-of-week
# Examples:
#   0 6 * * *    = 6:00 AM daily
#   0 */12 * * * = Every 12 hours
#   0 9 * * 1    = 9:00 AM every Monday
DAILY_REFRESH_CRON_SCHEDULE=0 6 * * *

# Timezone for scheduled jobs
DAILY_REFRESH_TIMEZONE=America/Los_Angeles

# Job execution timeout (in milliseconds)
# Default: 30 minutes (1800000ms)
DAILY_REFRESH_TIMEOUT=1800000

# Batch processing settings
DAILY_REFRESH_BATCH_SIZE=50        # Number of podcasts to process at once
DAILY_REFRESH_RATE_LIMIT_MS=1000   # Milliseconds between API calls
DAILY_REFRESH_MAX_RETRIES=3        # Retry attempts for failed requests
DAILY_REFRESH_RETRY_DELAY_MS=5000  # Delay between retries

# User processing settings
DAILY_REFRESH_BATCH_DELAY=2000     # Delay between user batches
DAILY_REFRESH_USER_DELAY=1000      # Delay between individual users

# -------------------------------------------------------------------
# EPISODE SYNC JOB
# -------------------------------------------------------------------
# Syncs new episodes from RSS feeds every 6 hours
# This job discovers new episodes and updates episode metadata

# Enable/disable the episode sync job
EPISODE_SYNC_ENABLED=true

# Cron schedule for episode sync (default: every 6 hours)
EPISODE_SYNC_CRON_SCHEDULE=0 */6 * * *

# Timezone for scheduled jobs
EPISODE_SYNC_TIMEZONE=America/Los_Angeles

# Batch processing settings for episode sync
EPISODE_SYNC_BATCH_SIZE=25         # Number of feeds to process at once
EPISODE_SYNC_RATE_LIMIT_MS=500     # Milliseconds between API calls
EPISODE_SYNC_MAX_RETRIES=3         # Retry attempts for failed requests
EPISODE_SYNC_RETRY_DELAY_MS=2000   # Delay between retries

# -------------------------------------------------------------------
# TRANSCRIPT WORKER JOB
# -------------------------------------------------------------------
# Nightly job to discover and store episode transcripts from Taddy API
# This job runs at 1 AM daily to fetch transcripts for new episodes

# Enable/disable the transcript worker job
TRANSCRIPT_WORKER_ENABLED=true

# Cron schedule for transcript worker (default: 1 AM daily)
# Format: minute hour day-of-month month day-of-week
# Examples:
#   0 1 * * *    = 1:00 AM daily
#   0 2 * * *    = 2:00 AM daily
#   0 1 * * 1    = 1:00 AM every Monday
TRANSCRIPT_WORKER_CRON=0 1 * * *

# Taddy API Tier Selection
# Controls which Taddy API tier to use for transcript retrieval
# Options: 'free' or 'business'
# - free: Uses Taddy Free tier (1,000 requests/month, pregenerated only)
# - business: Uses Taddy Business tier (higher limits, on-demand generation)
# Default: business (recommended for production)
TRANSCRIPT_TIER=business

# Lookback window: How many hours to scan for new episodes
# Default: 24 hours (episodes published in the last day)
TRANSCRIPT_LOOKBACK=24

# Request limits: Controls API usage and cost
TRANSCRIPT_MAX_REQUESTS=15         # Max Taddy API calls per run
TRANSCRIPT_CONCURRENCY=10          # Max simultaneous requests

# Advisory lock: Prevents overlapping runs (optional)
# Set to 'false' to disable locking mechanism
TRANSCRIPT_ADVISORY_LOCK=true

# -------------------------------------------------------------------
# LAST-10 RECHECK MODE (TRANSCRIPT_WORKER_L10D)
# -------------------------------------------------------------------
# This toggle controls whether the nightly transcript worker re-checks the last
# 10 episodes for each show. New behaviour (vNEXT):
#   • "true"  ➜ Re-check mode — ignore existing transcripts, process up to 10
#     most-recent episodes (overwrites duplicates).
#   • "false" ➜ Normal nightly mode — scan look-back window & skip episodes that
#     already have transcripts. (This is the default and most common setting.)
#   • To **pause** the worker entirely, set TRANSCRIPT_WORKER_ENABLED=false.
#
# Note the variable suffix has changed from TRANSCRIPT_WORKER_L10 →
# TRANSCRIPT_WORKER_L10D to emphasise the strict boolean semantics.
# Only the string "true" enables re-check mode; any other value is treated as
# false.
# Values: "true" or "false"
TRANSCRIPT_WORKER_L10D=false

# -------------------------------------------------------------------
# RSS FEED MATCHING CONFIGURATION
# -------------------------------------------------------------------
# Advanced RSS feed discovery and matching settings
# These settings control how the system matches Spotify shows to RSS feeds
# via the PodcastIndex API and episode verification

# Minimum similarity score for RSS feed matching (0.0-1.0)
# Higher values require more exact matches, lower values are more permissive
# Default: 0.8 (80% similarity required)
RSS_MATCH_THRESHOLD=0.8

# Similarity scoring weights for RSS feed matching
# These control the relative importance of different metadata fields
# All weights should sum to 1.0 for optimal results
# Default: 40% title, 40% description, 20% publisher
RSS_MATCH_TITLE_WEIGHT=0.4            # Weight for show title similarity
RSS_MATCH_DESCRIPTION_WEIGHT=0.4      # Weight for show description similarity  
RSS_MATCH_PUBLISHER_WEIGHT=0.2        # Weight for publisher similarity

# -------------------------------------------------------------------
# EPISODE NOTES WORKER JOB
# -------------------------------------------------------------------
# Nightly job to generate episode notes from transcripts using Gemini 1.5 Flash
# This job runs after the transcript worker to create structured notes for newsletters

# Enable/disable the episode notes worker job
NOTES_WORKER_ENABLED=true

# Lookback window: How many hours to scan for new transcripts needing notes
# Default: 24 hours (transcripts created in the last day)
# This should typically match or be slightly larger than TRANSCRIPT_LOOKBACK
NOTES_LOOKBACK_HOURS=24

# Testing mode: Process last 10 transcripts regardless of existing notes
# Options: "true" or "false"
# - "true": Overwrite notes for the 10 most recent transcripts (testing/debugging)
# - "false": Normal mode - only process transcripts without existing notes
# Default: false (normal production mode)
NOTES_WORKER_L10=false

# Concurrency control: Maximum simultaneous Gemini API calls
# Default: 30 (balances speed with API rate limits and cost control)
# Reduce if you hit rate limits or want to control costs
# Increase if you have higher API quotas and need faster processing
NOTES_MAX_CONCURRENCY=30

# Prompt template file: Path to the Markdown file containing the LLM prompt
# Default: prompts/episode-notes.md
# This file contains the instructions sent to Gemini for generating episode notes
# Modify this file to adjust the style and content of generated notes
NOTES_PROMPT_PATH=prompts/episode-notes.md

# -------------------------------------------------------------------
# NOTE ON TRANSCRIPT STATUS COLUMNS (vNEXT July 2025)
# -------------------------------------------------------------------
# The transcripts table now contains two status columns (`initial_status`,
# `current_status`) plus optional `error_details`. The nightly worker writes
# *both* columns. Allowed status values:
#   full | partial | processing | no_transcript_found | no_match | error
# Legacy values (available, pending, not_found) are no longer used.
# This change requires running migration:
#   supabase/migrations/20250701120000_rename_status_add_current_status.sql

# -------------------------------------------------------------------
# NEWSLETTER EDITION WORKER JOB
# -------------------------------------------------------------------
# Nightly job to generate personalized newsletter editions from episode notes
# This job runs after the episode notes worker to create user-specific newsletters

# Enable/disable the newsletter edition worker job
EDITION_WORKER_ENABLED=true

# Cron schedule for edition worker (default: 3 AM daily)
# Format: minute hour day-of-month month day-of-week
# Examples:
#   0 3 * * *    = 3:00 AM daily (default)
#   0 4 * * *    = 4:00 AM daily
#   0 3 * * 1    = 3:00 AM every Monday
EDITION_WORKER_CRON=0 3 * * *

# Lookback window: How many hours to scan for new episode notes
# Default: 24 hours (episode notes created in the last day)
# This should typically match or be slightly larger than NOTES_LOOKBACK_HOURS
EDITION_LOOKBACK_HOURS=24

# Testing mode: Overwrite the last 10 newsletter editions regardless of user
# Options: "true" or "false"
# - "true": Overwrite content for the 10 most recent newsletter editions (testing/debugging)
# - "false": Normal mode - only create new editions for users without recent editions
# Default: false (normal production mode)
EDITION_WORKER_L10=false

# Prompt template file: Path to the Markdown file containing the newsletter prompt
# Default: prompts/newsletter-edition.md
# This file contains the instructions sent to Gemini for generating newsletter content
# Modify this file to adjust the style and content of generated newsletters
EDITION_PROMPT_PATH=prompts/newsletter-edition.md

# -------------------------------------------------------------------
# NEWSLETTER SEND WORKER JOB
# -------------------------------------------------------------------
# Nightly job to send newsletter editions to users via email
# This job runs at 5 AM on weekdays to deliver newsletters to users

# Enable/disable the newsletter send worker job
SEND_WORKER_ENABLED=true

# Cron schedule for send worker (default: 5 AM Mon-Fri)
# Format: minute hour day-of-month month day-of-week
# Examples:
#   0 5 * * 1-5  = 5:00 AM Monday through Friday (default)
#   0 6 * * *    = 6:00 AM daily
#   0 5 * * 1    = 5:00 AM every Monday
SEND_WORKER_CRON=0 5 * * 1-5

# Lookback window: How many hours to scan for newsletter editions to send
# Default: 24 hours (editions created in the last day)
# This should typically match or be slightly larger than EDITION_LOOKBACK_HOURS
SEND_LOOKBACK=24

# Testing mode: Send last 10 editions to test email without updating sent_at
# Options: "true" or "false"
# - "true": Send last 10 editions to TEST_RECEIVER_EMAIL (testing mode)
# - "false": Normal mode - send to real users and update sent_at timestamps
# Default: false (normal production mode)
SEND_WORKER_L10=false

# ===================================================================
# CLIENT APPLICATION (VITE/REACT)
# ===================================================================
# These variables are used by the React frontend application
# They MUST start with VITE_ to be accessible in the browser

# API Base URL: Where the frontend will make API requests
VITE_API_BASE_URL=http://localhost:3001

# Base URL: The URL where the frontend application is hosted
VITE_BASE_URL=http://localhost:3000

# ===================================================================
# DEVELOPMENT & TESTING
# ===================================================================
# These settings are primarily used during development and testing

# Development mode settings
# (Add any development-specific variables here)

# ===================================================================
# PRODUCTION NOTES
# ===================================================================
# When deploying to production:
# 1. Copy this file to .env.production
# 2. Update all URLs to use your production domains
# 3. Use strong, unique secrets for JWT_SECRET and TOKEN_ENC_KEY
# 4. Set NODE_ENV=production
# 5. Set LOG_LEVEL=info or warn
# 6. Set STRUCTURED_LOGGING=true
# 7. Review and adjust all timeout and batch size settings
# 8. Ensure all API keys are for production services
#
# SECURITY CHECKLIST:
# □ All placeholder values replaced with real credentials
# □ JWT_SECRET is at least 32 characters and cryptographically secure
# □ TOKEN_ENC_KEY is exactly 32 characters
# □ SUPABASE_SERVICE_ROLE_KEY is not exposed in client code
# □ Production credentials are different from development
# □ All API keys are active and have appropriate permissions
# =================================================================== 